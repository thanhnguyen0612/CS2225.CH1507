{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[CS2225]Testing_6_fruits_detection_model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Ze_Ve2hcVxQhKXiJFGrAGdpLg1_HXJwn",
      "authorship_tag": "ABX9TyOneyhyw8n5fvJgM4Nm/u+9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanhnguyen0612/CS2225.CH1507/blob/master/%5BCS2225%5DTesting_6_fruits_detection_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf5T0Bb-fQbR"
      },
      "source": [
        "#1. Cài đặt Object detection API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15AQ51l2rgIA"
      },
      "source": [
        "import os\r\n",
        "import pathlib\r\n",
        "\r\n",
        "# Clone the tensorflow models repository if it doesn't already exist\r\n",
        "if \"models\" in pathlib.Path.cwd().parts:\r\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\r\n",
        "    os.chdir('..')\r\n",
        "elif not pathlib.Path('models').exists():\r\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpP_NAcIrkqQ"
      },
      "source": [
        "%%bash\r\n",
        "cd models/research/\r\n",
        "protoc object_detection/protos/*.proto --python_out=.\r\n",
        "cp object_detection/packages/tf2/setup.py .\r\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fzyRjnWfblz"
      },
      "source": [
        "#2. Download model đã được nhóm train sẵn và upload lên goodle drive:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psK2ukEBr9ZJ"
      },
      "source": [
        "import gdown\r\n",
        "\r\n",
        "!mkdir '/content/trained_model'; # tạo folder 'trained_model' trên google instance, để chứa model download\r\n",
        "\r\n",
        "url = 'https://drive.google.com/uc?id=1WCOahi-cR1p88MtyH9QdgW465Quqenz4' #URL cố định dùng để download.\r\n",
        "output = '/content/trained_model/trained_model.zip' \r\n",
        "gdown.download(url, output, quiet=False)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpArC98uyQzz"
      },
      "source": [
        "# Unzip và remove zip file. Kết quả sẽ được folder CS2225 trên google instance, trong folder này chứ model đã được train sẵn của nhóm.\r\n",
        "!unzip '/content/trained_model/trained_model.zip'\r\n",
        "!rm -r '/content/trained_model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq0INa69gip6"
      },
      "source": [
        "#3. Import thư viện và config cần thiết trước khi run test:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI6cNw3orpDS"
      },
      "source": [
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import os\r\n",
        "import random\r\n",
        "import io\r\n",
        "import imageio\r\n",
        "import glob\r\n",
        "import scipy.misc\r\n",
        "import numpy as np\r\n",
        "from six import BytesIO\r\n",
        "from PIL import Image, ImageDraw, ImageFont\r\n",
        "from IPython.display import display, Javascript\r\n",
        "from IPython.display import Image as IPyImage\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import config_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "from object_detection.utils import colab_utils\r\n",
        "from object_detection.builders import model_builder\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2OceXA9r0_a"
      },
      "source": [
        "#Hàm load image\r\n",
        "def load_image_into_numpy_array(path):\r\n",
        "  \"\"\"Load an image from file into a numpy array.\r\n",
        "\r\n",
        "  Puts image into numpy array to feed into tensorflow graph.\r\n",
        "  Note that by convention we put it into a numpy array with shape\r\n",
        "  (height, width, channels), where channels=3 for RGB.\r\n",
        "\r\n",
        "  Args:\r\n",
        "    path: the file path to the image\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\r\n",
        "  \"\"\"\r\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n",
        "  image = Image.open(BytesIO(img_data))\r\n",
        "  (im_width, im_height) = image.size\r\n",
        "  return np.array(image.getdata()).reshape(\r\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq6Mv5PIr47v"
      },
      "source": [
        "pipeline_file = '/content/CS225/result_model/pipeline.config'\r\n",
        "#recover our saved model\r\n",
        "pipeline_config = pipeline_file\r\n",
        "\r\n",
        "#\r\n",
        "model_dir = '/content/CS225/output_model/ckpt-3'\r\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_file)\r\n",
        "model_config = configs['model']\r\n",
        "detection_model = model_builder.build(\r\n",
        "      model_config=model_config, is_training=False)\r\n",
        "\r\n",
        "# Restore checkpoint\r\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\r\n",
        "      model=detection_model)\r\n",
        "ckpt.restore(os.path.join('/content/CS225/output_model/ckpt-3'))\r\n",
        "\r\n",
        "\r\n",
        "def get_model_detection_function(model):\r\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\r\n",
        "\r\n",
        "  @tf.function\r\n",
        "  def detect_fn(image):\r\n",
        "    \"\"\"Detect objects in image.\"\"\"\r\n",
        "\r\n",
        "    image, shapes = model.preprocess(image)\r\n",
        "    prediction_dict = model.predict(image, shapes)\r\n",
        "    detections = model.postprocess(prediction_dict, shapes)\r\n",
        "\r\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\r\n",
        "\r\n",
        "  return detect_fn\r\n",
        "\r\n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpmt6bFA1a_e"
      },
      "source": [
        "#map labels for inference decoding\r\n",
        "label_map_path = configs['eval_input_config'].label_map_path\r\n",
        "label_map = label_map_util.load_labelmap('/content/CS225/fruit_label_map.pbtxt')\r\n",
        "categories = label_map_util.convert_label_map_to_categories(\r\n",
        "    label_map,\r\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\r\n",
        "    use_display_name=True)\r\n",
        "category_index = label_map_util.create_category_index(categories)\r\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyAgxT5eg6Jd"
      },
      "source": [
        "#4. Cách test 1: test bằng cách input 01 hình ảnh:\r\n",
        "* Note: có 2 cách test: input hình ảnh và chụp hình từ webcam (xem mục số 5)\r\n",
        "* Trong folder 'CS225/test_images/' **(folder này đã được download ở mục 2)** nhóm đã chuẩn bị sẵn 1 số hình ngẫu nhiên để thuận tiện việc test.\r\n",
        "* Cách run test: Gán biến **img** bằng đường dẫn dẫn tới hình ảnh muốn test **(hình ảnh nằm trên google instance đang connect)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Uv8W752Am1"
      },
      "source": [
        "import random\r\n",
        "import glob\r\n",
        "import cv2\r\n",
        "\r\n",
        "#Randomly chọn hình ảnh trong folder CS2225/test_images\r\n",
        "TEST_IMAGE_PATHS = glob.glob('/content/CS2225/test_images/*.jpg')\r\n",
        "img = random.choice(TEST_IMAGE_PATHS)\r\n",
        "\r\n",
        "image_np = load_image_into_numpy_array(img)\r\n",
        "\r\n",
        "input_tensor = tf.convert_to_tensor(\r\n",
        "    np.expand_dims(image_np, 0), dtype=tf.float32)\r\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\r\n",
        "\r\n",
        "label_id_offset = 1\r\n",
        "image_np_with_detections = image_np.copy()\r\n",
        "\r\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "      image_np_with_detections,\r\n",
        "      detections['detection_boxes'][0].numpy(),\r\n",
        "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\r\n",
        "      detections['detection_scores'][0].numpy(),\r\n",
        "      category_index,\r\n",
        "      use_normalized_coordinates=True,\r\n",
        "      max_boxes_to_draw=200,\r\n",
        "      min_score_thresh=.5,\r\n",
        "      agnostic_mode=False,\r\n",
        "      line_thickness=10\r\n",
        ")\r\n",
        "\r\n",
        "plt.figure(figsize=(12,16))\r\n",
        "plt.imshow(image_np_with_detections)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FnO2TsJjjNY"
      },
      "source": [
        "#5. Cách test 2: Lấy hình được chụp từ webcam\r\n",
        "* Webcam sẽ được bật, click 1 click để chụp hình từ webcam\r\n",
        "* Output: hình ảnh được chụp cùng với bounding box, label name, score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svidlLt0kL-a"
      },
      "source": [
        "# Define hàm take_photo: làm nhiệm vụ bật webcam & chụp hình\r\n",
        "from IPython.display import HTML, Audio\r\n",
        "from google.colab.output import eval_js\r\n",
        "from base64 import b64decode\r\n",
        "import numpy as np\r\n",
        "import io\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "VIDEO_HTML = \"\"\"\r\n",
        "<div class=\"video_container\">\r\n",
        "  <video autoplay\r\n",
        "   width=%d height=%d></video>\r\n",
        "  <div style='position: absolute;top: 40px; left: 40px; font-size: 40px; color: green;'>Click to save!</div>\r\n",
        "</div>\r\n",
        "<script>\r\n",
        "var video = document.querySelector('video')\r\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\r\n",
        "  .then(stream=> video.srcObject = stream)\r\n",
        "  \r\n",
        "var data = new Promise(resolve=>{\r\n",
        "  video.onclick = ()=>{\r\n",
        "    var canvas = document.createElement('canvas')\r\n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight]\r\n",
        "    canvas.width = w\r\n",
        "    canvas.height = h\r\n",
        "    canvas.getContext('2d')\r\n",
        "          .drawImage(video, 0, 0, w, h)\r\n",
        "    video.srcObject.getVideoTracks()[0].stop()\r\n",
        "    video.replaceWith(canvas)\r\n",
        "    resolve(canvas.toDataURL('image/jpeg', %f))\r\n",
        "  }\r\n",
        "})\r\n",
        "</script>\r\n",
        "\"\"\"\r\n",
        "OUTPUT_IMG_FROM_WEBCAM_PATH = '/content/test_img.jpg'\r\n",
        "def take_photo(filename=OUTPUT_IMG_FROM_WEBCAM_PATH, quality=0.8, size=(800,600)):\r\n",
        "  handle = display(HTML(VIDEO_HTML % (size[0],size[1],quality)), display_id='videoHTML')\r\n",
        "  data = eval_js(\"data\")\r\n",
        "  binary = b64decode(data.split(',')[1])\r\n",
        "  \r\n",
        "  if filename:\r\n",
        "    f = io.BytesIO(binary)\r\n",
        "    Image.open(f).save(filename)\r\n",
        "  else:\r\n",
        "    f = io.BytesIO(binary)\r\n",
        "    return np.asarray(Image.open(f))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RALFP6O2kYJq"
      },
      "source": [
        "import random\r\n",
        "import glob\r\n",
        "import cv2\r\n",
        "\r\n",
        "take_photo()\r\n",
        "img = OUTPUT_IMG_FROM_WEBCAM_PATH\r\n",
        "image_np = load_image_into_numpy_array(img)\r\n",
        "\r\n",
        "# Things to try:\r\n",
        "# Flip horizontally\r\n",
        "# image_np = np.fliplr(image_np).copy()\r\n",
        "\r\n",
        "# Convert image to grayscale\r\n",
        "# image_np = np.tile(\r\n",
        "#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\r\n",
        "\r\n",
        "input_tensor = tf.convert_to_tensor(\r\n",
        "    np.expand_dims(image_np, 0), dtype=tf.float32)\r\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\r\n",
        "\r\n",
        "label_id_offset = 1\r\n",
        "image_np_with_detections = image_np.copy()\r\n",
        "\r\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "      image_np_with_detections,\r\n",
        "      detections['detection_boxes'][0].numpy(),\r\n",
        "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\r\n",
        "      detections['detection_scores'][0].numpy(),\r\n",
        "      category_index,\r\n",
        "      use_normalized_coordinates=True,\r\n",
        "      max_boxes_to_draw=200,\r\n",
        "      min_score_thresh=.5,\r\n",
        "      agnostic_mode=False,\r\n",
        "      line_thickness=12\r\n",
        ")\r\n",
        "\r\n",
        "plt.figure(figsize=(12,16))\r\n",
        "plt.imshow(image_np_with_detections)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}